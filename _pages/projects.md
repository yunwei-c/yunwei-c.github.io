---
layout: archive
title: "Projects"
permalink: /projects/
author_profile: true
---

<div style="float:left">
<img src="/images/Stretch.png" align="left" width="200px" height="200px" >
</div>
<div style="margin:8px;float:left;width:75%;text-align:justify;line-height:18px">
<b>Telescopic Visual Storytelling</b>
<small><br>Distilled nouns and verbs from a sequence of images and utilized knowledge graph to find the important relations between nouns. Dynamically performed recurrent Transformer to generated stories with diverse length. The human evaluation showed that our model can generate longer stories, even when the input images are incohert.
</div>
<div style="clear:both"></div>
<hr> 


<div style="float:left">
<img src="/images/AAAI_DSTC.png" align="left" width="200px" height="200px" >
</div>
<div style="margin:8px;float:left;width:75%;text-align:justify;line-height:18px">
<b>Multi-modal Dialog System</b>
<small><br>Proposed a multi-step joint-modality attention network based on recurrent neural network to reason on multiple modalities, including audio, vision, and language. The model jointly considered both visual and textual representations in each reasoning process to better integrate information from dynamic scenes.
<br>
<a href="https://arxiv.org/abs/2001.06206">[Paper Link]</a></small>
</div>
<div style="clear:both"></div>
<hr> 

<div style="float:left">
<img align="left" width="200px" height="200px" src="/images/SIGIR.png">
</div>
<div style="margin:8px;float:left;width:75%;text-align:justify;line-height:18px">
<b>Multiview Items Recommendation</b>
<small><br>Developed a GNN-based recommendation model which provides superior recommendations by describing items from user and entity angles. Designed user-oriented modules that aggregate features to make personalized recommendations and a mixing layer which contrasts layer-wise GCN to obtain comprehensive features from internal entity-entity interactions. 
<br>
<a href="https://arxiv.org/abs/2005.12516">[Paper Link]</a></small>
</div>
<div style="clear:both"></div>
<hr> 


<div style="float:left">
<img align="left" width="200" height="200" src="/images/SW.png">
</div>
<div style="margin:8px;float:left;width:75%;text-align:justify;line-height:18px">
<b>Stage-Wise Training for GNN-based Recommender Model</b>
<small><br>Applied stage-wise training on two state-of-the-art recommendation models, RippleNet and Knowledge Graph Convolutional Networks (KGCN), and evaluated the performance on six real world datasets. The result of the experiments showed that stage-wise training strategy can help both models to collect more information from the KG and improve the recommendation performance. 
<br>
<a href="https://arxiv.org/abs/1908.05611">[Paper Link]</a></small>
</div>
<div style="clear:both"></div>
<hr> 


<div style="float:left">
<img align="left" width="200" height="200" src="/images/ACCESS.png">
</div> 
<div style="margin:8px;float:left;width:75%;text-align:justify;line-height:18px">
<b>Luminance Variation Resistant Remote-PPG</b>
<small><br>Collected drivers’ facial dataset (2.7M continuous images) in different outdoor scenarios, including day time and night. Developed an Adaptive Neural Network Model Selection algorithm to eliminate facial luminance variation noise from rPPG signal and successfully reduced the mean absolute error from 14.71 bpm to 4.51 bpm.
<br>
<a href="https://ieeexplore.ieee.org/document/8701432">[Paper Link]</a> <a href="https://www.youtube.com/watch?v=cvw8AeakBt8&feature=youtu.be">[Demo Video]</a> </small>
</div>
<div style="clear:both"></div>
<hr> 


<div style="float:left">
<img align="left" width="200" height="150" src="/images/ACCV.png">
</div> 
<div style="margin:8px;float:left;width:75%;text-align:justify;line-height:18px">
<b>Motion Robust Remote-PPG </b>
<small><br>Built a face tracking algorithm to extract heart rate signal from driver’s face in continuous images sequence. Developed machine learning approach to eliminate rPPG noise. This work is first of its kind as the traditional rPPG work consider only in indoor environment.
<br>
<a href="https://link.springer.com/chapter/10.1007/978-3-319-54407-6_31">[Paper Link]</a> </small>
</div>
<div style="clear:both"></div>
<hr> 
