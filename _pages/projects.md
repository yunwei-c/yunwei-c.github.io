---
layout: archive
title: "Projects"
permalink: /projects/
author_profile: true
---

<div style="float:left">
<img src="/images/AAAI_DSTC.png" align="left" width="300" height="300" >
</div>
<div style="margin:10px;float:left;width:75%;text-align:justify">
<b>Multi-modal Dialog System</b>
<br>Proposed a multi-step joint-modality attention network based on recurrent neural network to reason on multiple modalities including audio, vision, and language. The jointly considered both visual and textual representations in each reasoning process to better integrate information from dynamic scenes.
<br>
 <a href="https://arxiv.org/abs/2001.06206">[Paper Link]</a>
</div>
<div style="clear:both"></div>


<div style="float:left">
<img align="left" width="200px" height="200px" src="/images/SIGIR.png">
</div>
<div style="margin:10px;float:left;width:75%">
<b>Multiview Items Recommendation</b>
<br>Developed a GNN-based recommendation model which provides superior recommendations by describing items from user and entity angles. Designed user-oriented modules that aggregate features to make personalized recommendations and a mixing layer which contrasts layer-wise GCN to obtain comprehensive features from internal entity-entity interactions. 
<br>
<a href="https://arxiv.org/abs/2005.12516">[Paper Link]</a>
</div>
<div style="clear:both"></div>

 
<img align="left" width="200" height="200" src="/images/SW.png">
<b>Stage-Wise Training for GNN-based Recommender Model</b>
<br>Applied stage-wise training on two state-of-the-art recommendation models, RippleNet and Knowledge Graph Convolutional Networks (KGCN), and evaluated the performance on six real world datasets. The result of the experiments shows that stage-wise training strategy can help both models to collect more information from the KG and improve the recommendation performance. 
<br>[[Paper Link]](https://arxiv.org/abs/1908.05611)

 
<img align="left" width="200" height="200" src="/images/ACCESS.png">
<b>Luminance Variation Resistant Remote-PPG</b>
<br>Collected drivers’ facial dataset (2.7M continuous images) in different outdoor scenarios, including day time and night. Developed an Adaptive Neural Network Model Selection algorithm to eliminate facial luminance variation noise from rPPG signal and  successfully reduced the mean absolute error from 14.71 bpm to 4.51 bpm.
<br>[[Paper Link]](https://ieeexplore.ieee.org/document/8701432) [[Video]](https://www.youtube.com/watch?v=cvw8AeakBt8&feature=youtu.be)


<img align="left" width="200" height="150" src="/images/ACCV.png">
<b>Motion Robust Remote-PPG </b>
<br>Built a face tracking algorithm to extract heart rate signal from driver’s face in continuous images sequence. Developed machine learning approach to eliminate rPPG noise. This work is first of its kind as the traditional rPPG work consider only in indoor environment.
<br>[[Paper Link]](https://link.springer.com/chapter/10.1007/978-3-319-54407-6_31)

